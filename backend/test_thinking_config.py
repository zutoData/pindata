#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ€è€ƒè¿‡ç¨‹é…ç½®ä¼ é€’å’Œå¤„ç†
"""

import json

def test_thinking_process_config():
    """æµ‹è¯•æ€è€ƒè¿‡ç¨‹é…ç½®çš„ä¼ é€’å’Œå¤„ç†"""
    
    # æ¨¡æ‹Ÿå‰ç«¯ä¼ é€’çš„é…ç½®
    frontend_config = {
        "selected_files": [
            {"id": "1", "name": "test.md", "path": "/test/test.md", "size": 1024}
        ],
        "dataset_config": {
            "type": "qa-pairs",
            "format": "Alpaca",
            "name": "æµ‹è¯•æ•°æ®é›†",
            "description": "æµ‹è¯•æ€è€ƒè¿‡ç¨‹åŠŸèƒ½"
        },
        "model_config": {
            "id": "test-model-id",
            "name": "GPT-4",
            "provider": "openai"
        },
        "processing_config": {
            "dataset_type": "qa-pairs",
            "output_format": "Alpaca",
            "chunk_size": 1000,
            "chunk_overlap": 200,
            "custom_prompt": "ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹",
            "temperature": 0.7,
            "max_tokens": 2000,
            "batch_size": 10,
            # æ€è€ƒè¿‡ç¨‹é…ç½®
            "enableThinkingProcess": True,
            "reasoningExtractionMethod": "tag_based",
            "reasoningExtractionConfig": {"tag": "thinking"},
            "distillationPrompt": "è¯·è¯¦ç»†è¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬åˆ†ææ­¥éª¤å’Œæ¨ç†é€»è¾‘",
            "includeThinkingInOutput": True
        }
    }
    
    print("âœ… å‰ç«¯é…ç½®ç»“æ„:")
    print(json.dumps(frontend_config, indent=2, ensure_ascii=False))
    
    # æ¨¡æ‹Ÿåç«¯å¤„ç†é€»è¾‘
    processing_config = frontend_config["processing_config"]
    
    # æå–æ€è€ƒè¿‡ç¨‹é…ç½®
    enable_thinking = processing_config.get('enableThinkingProcess', False)
    include_thinking_in_output = processing_config.get('includeThinkingInOutput', False)
    reasoning_extraction_method = processing_config.get('reasoningExtractionMethod')
    reasoning_extraction_config = processing_config.get('reasoningExtractionConfig', {})
    distillation_prompt = processing_config.get('distillationPrompt', '')
    
    print("\nâœ… åç«¯è§£æçš„é…ç½®:")
    print(f"  - å¯ç”¨æ€è€ƒè¿‡ç¨‹: {enable_thinking}")
    print(f"  - åŒ…å«æ€è€ƒè¿‡ç¨‹: {include_thinking_in_output}")
    print(f"  - æå–æ–¹æ³•: {reasoning_extraction_method}")
    print(f"  - æå–é…ç½®: {reasoning_extraction_config}")
    print(f"  - è’¸é¦æç¤ºè¯: {'å·²é…ç½®' if distillation_prompt else 'æœªé…ç½®'}")
    
    # éªŒè¯é…ç½®å®Œæ•´æ€§
    validation_errors = []
    
    if enable_thinking:
        # æ¨¡æ‹Ÿæ”¯æŒæ¨ç†çš„æ¨¡å‹é…ç½®éªŒè¯
        supports_reasoning = True  # å‡è®¾æ¨¡å‹æ”¯æŒæ¨ç†
        
        if supports_reasoning:
            if not reasoning_extraction_method:
                validation_errors.append("æ”¯æŒæ¨ç†çš„æ¨¡å‹éœ€è¦é…ç½®æå–æ–¹æ³•")
            
            if reasoning_extraction_method == 'tag_based' and not reasoning_extraction_config.get('tag'):
                validation_errors.append("æ ‡ç­¾æ¨¡å¼éœ€è¦æŒ‡å®šæ ‡ç­¾åç§°")
                
        else:
            if include_thinking_in_output and not distillation_prompt:
                validation_errors.append("ä¸æ”¯æŒæ¨ç†çš„æ¨¡å‹éœ€è¦è’¸é¦æç¤ºè¯")
    
    if validation_errors:
        print("\nâŒ é…ç½®éªŒè¯å¤±è´¥:")
        for error in validation_errors:
            print(f"  - {error}")
        return False
    else:
        print("\nâœ… é…ç½®éªŒè¯é€šè¿‡!")
        return True

def test_llm_config_examples():
    """æµ‹è¯•ä¸åŒLLMé…ç½®çš„æ€è€ƒè¿‡ç¨‹å¤„ç†"""
    
    # æ”¯æŒæ¨ç†çš„æ¨¡å‹é…ç½®
    reasoning_model = {
        "supports_reasoning": True,
        "reasoning_extraction_method": "tag_based",
        "reasoning_extraction_config": {"tag": "thinking"}
    }
    
    # ä¸æ”¯æŒæ¨ç†çš„æ¨¡å‹é…ç½®
    non_reasoning_model = {
        "supports_reasoning": False,
        "reasoning_extraction_method": None,
        "reasoning_extraction_config": None
    }
    
    print("\nâœ… LLMé…ç½®ç¤ºä¾‹:")
    print("æ”¯æŒæ¨ç†çš„æ¨¡å‹:", json.dumps(reasoning_model, indent=2, ensure_ascii=False))
    print("ä¸æ”¯æŒæ¨ç†çš„æ¨¡å‹:", json.dumps(non_reasoning_model, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    print("ğŸ” æµ‹è¯•æ€è€ƒè¿‡ç¨‹é…ç½®ä¼ é€’å’Œå¤„ç†")
    print("=" * 50)
    
    success = test_thinking_process_config()
    test_llm_config_examples()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ€è€ƒè¿‡ç¨‹é…ç½®å·²æ­£ç¡®å®ç°ã€‚")
    else:
        print("\nï¿½ï¿½ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®é€»è¾‘ã€‚") 